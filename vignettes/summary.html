<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Abstract</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Abstract</h2>

<p>The kane2017 package utilizes the data published in Williams Online Catalog to assess the number of students with Chinese/Cantonese/Japanese origins and compare their academic achievement with other students. This is done for 15 years from 2002 - 2016 by scanning the data directly from the text version of the webpages. A sequences of statistical comparisons will be utilized to examine the academic achievement of (partial) Asian International/American students.</p>

<h2>Introduction</h2>

<p>College admission, espeically recently, has been suspected of raising a higher standard towards Asian students. Though it is unclear that the admission standard has been raised at Williams, looking at the Asian students ratio of attaining Latin honors will be a useful tool in assessing the overall academic performance of Asian American students and can thus further reflect on the bar set during admission. The package kane2017 employs string manipulation(splitting, pattern detection) to split each string into its last name.</p>

<p>The data set is further manipulated by comparing each of the last names to a pre-existing list of possible last names of Asian origin. But processing whether if these last names are of Asian origin, we can then figure out the ratio of Latin honors among Asian students. </p>

<h2>Data</h2>

<p>The information used to construct the dataset is taken from the Registrar office. The text file is manually converted from the catalog through copying and pasting. </p>

<p>Though the input are quite concise, since last names and honors are the only things we need, we need to cut down the strings. </p>

<p>For example, for input: <em>+Kathleen Malone Palmer, with highest honors in Neuroscience, readHonor will use 
      unlist(str_split(data[j],&quot;,&quot;))
      and 
      gsub(&quot;.</em> &quot;, &quot;&quot;, name)
      to turn the original string into Palmer.
After obtaining a list of last names, we then compare the last names with the given list of last names. Now we have chineseLastName, japaneseLastName, cantoneseLastName, and totalVeri, which is the collection of the previous three. 
The name verifies and years are previously stored through RData and passed into readHonor(data, verifier)</p>

<p>readHonor will then return a data.frame as below</p>

<pre><code class="r">readHonor(Data2012,chineseLastName)
</code></pre>

<pre><code>##     name honor SummaPer MagnaAbovePer CumAbovePer percentSigma percentPhi
## 1   Meng Summa 6.060606      24.24242    36.36364     9.433962   8.823529
## 2   Wang Summa 6.060606      24.24242    36.36364     9.433962   8.823529
## 3     Li Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 4     Li Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 5   Ting Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 6  Xiong Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 7     Yu Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 8  Zheng Magna 6.060606      24.24242    36.36364     9.433962   8.823529
## 9    Cha   Cum 6.060606      24.24242    36.36364     9.433962   8.823529
## 10 Huang   Cum 6.060606      24.24242    36.36364     9.433962   8.823529
## 11  Song   Cum 6.060606      24.24242    36.36364     9.433962   8.823529
## 12  Yong   Cum 6.060606      24.24242    36.36364     9.433962   8.823529
## 13    Bi       6.060606      24.24242    36.36364     9.433962   8.823529
## 14 Chang       6.060606      24.24242    36.36364     9.433962   8.823529
## 15  Chen       6.060606      24.24242    36.36364     9.433962   8.823529
## 16   Chu       6.060606      24.24242    36.36364     9.433962   8.823529
## 17   Cui       6.060606      24.24242    36.36364     9.433962   8.823529
## 18  Dong       6.060606      24.24242    36.36364     9.433962   8.823529
## 19 Huang       6.060606      24.24242    36.36364     9.433962   8.823529
## 20 Huang       6.060606      24.24242    36.36364     9.433962   8.823529
## 21  Kang       6.060606      24.24242    36.36364     9.433962   8.823529
## 22   Lin       6.060606      24.24242    36.36364     9.433962   8.823529
## 23   Lin       6.060606      24.24242    36.36364     9.433962   8.823529
## 24   Liu       6.060606      24.24242    36.36364     9.433962   8.823529
## 25   Liu       6.060606      24.24242    36.36364     9.433962   8.823529
## 26  Shen       6.060606      24.24242    36.36364     9.433962   8.823529
## 27 Sheng       6.060606      24.24242    36.36364     9.433962   8.823529
## 28  Wang       6.060606      24.24242    36.36364     9.433962   8.823529
## 29  Wang       6.060606      24.24242    36.36364     9.433962   8.823529
## 30  Wang       6.060606      24.24242    36.36364     9.433962   8.823529
## 31   Yun       6.060606      24.24242    36.36364     9.433962   8.823529
## 32  Zeng       6.060606      24.24242    36.36364     9.433962   8.823529
## 33 Zhang       6.060606      24.24242    36.36364     9.433962   8.823529
</code></pre>

<p>By using read(honor, verifier), we can then utilize the data frame and look at the ratio of students of Asian origins with different Latin honors in comparison to the average ratio of Latin honors among college students. </p>

<pre><code class="r">plot(read(&quot;Summa&quot;,chineseLastName),  ylab=&quot;Percent Summa Cum Laude&quot;)
</code></pre>

<pre><code>## [1] &quot;Summa&quot;
</code></pre>

<pre><code class="r">title(main=&quot;Summa Cum Laude Percentage 2002- 2016&quot;)
abline(a=2, b=0)
</code></pre>

<p><img src="figure/summa-1.png" alt="plot of chunk summa"></p>

<pre><code>## [1] &quot;Magna&quot;
</code></pre>

<p><img src="figure/magna-1.png" alt="plot of chunk magna"></p>

<pre><code class="r">plot(read(&quot;Cum&quot;,chineseLastName), xlab=&quot;Year&quot;, ylab=&quot;Percent Cum Laude&quot;)
</code></pre>

<pre><code>## [1] &quot;Cum&quot;
</code></pre>

<pre><code class="r">title(main=&quot;Cum Laude Percentage 2002- 2016&quot;)
abline(a=35, b=0)
</code></pre>

<p><img src="figure/cum-1.png" alt="plot of chunk cum"></p>

<p>By attaining the mean value of different origins over 16 years through originAverage(verifier) that takes in country of origin, one is able to compare the average Latin honors with that of students of Asian descend. </p>

<pre><code class="r">plot(originAverage(&quot;Cum&quot;), ylab=&quot;Average Percent Cum Laude&quot;)
</code></pre>

<pre><code>## [1] &quot;Cum&quot;
## [1] &quot;Cum&quot;
## [1] &quot;Cum&quot;
</code></pre>

<pre><code class="r">title(main=&quot;average Cum Laude 2002- 2016&quot;)
abline(a=35, b=0)
</code></pre>

<p><img src="figure/tenYearAverage-1.png" alt="plot of chunk tenYearAverage"></p>

<h2>Conclusion</h2>

<p>The summary statstics indicates that according to the Asian last name reference sheets, students of Asian origins tend to be significantly overachieving, with an overall average Cum Laude percentage around 7.5% higher than the average 35%. Also, in the scatterplot graphs, the majority of all stats over years is higher than the average ratio of that particualr honor and above. Thus, it can be inferred that Asian students tend to be more academically achieving. Such conclusion, therefore, should serve as a powerful evidence towards some of the variations in admission standards Asian students might be facing. </p>

<p>However, this package is still incomplete in many ways. First, distinguishing last names from its linguistic composition can be extremely ambiguous. It doesn&#39;t take into account some of the identical last names different cultures can share. Also, it doesn&#39;t take into account students of mixed racial identity. Therefore, the next step will be to incorporate more last name recognizing templates as well as trying to distinguish last names of ambiguous identities base on first names. </p>

</body>

</html>
